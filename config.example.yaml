############ Configuration Example ############
# This contains an example configuration file for OpenMeter.
# Values here match the default configuration, unless noted otherwise.
###############################################


###### Server configuration ######
## Address the server listens on
address: 127.0.0.1:8888 # Default: :8888

# ## Aggregation configuration
# # default values
# aggregation:
#     ## ClickHouse connection configuration
#     clickhouse:
#         address: 127.0.0.1:9000
#         database: openmeter
#         password: default
#         tls: false
#         username: default
#

## Deduplication of metering events
dedupe:
    enabled: true # Default: false

    ## Dedupe driver: memory, redis
    driver: memory
    # ## Redis connection config, only used when driver=redis
    # config:
    #     address: 127.0.0.1:6379
    #     database: 0
    #     expiration: 24h
    #     password: ""
    #     sentinel:
    #         enabled: false
    #         mastername: ""
    #     size: 128
    #     tls:
    #         enabled: false
    #         insecureSkipVerify: false
    #     username: ""

# ## Environment name
# environment: unknown

# ## Namespace configuration
# namespace:
#     default: default
#     disablemanagement: false

# ## Metering event ingestion
# ingest:
#     ## Kafka connection configuration
#     kafka:
#         broker: 127.0.0.1:29092
#         eventstopictemplate: om_%s_events
#         partitions: 1
#         saslmechanisms: ""
#         saslpassword: ""
#         saslusername: ""
#         securityprotocol: ""

# ## Auth configuration for use with the Web Portal
# portal:
#     cors:
#         enabled: true
#     enabled: false
#     tokenexpiration: 1h
#     tokensecret: ""


###### Sink-Worker configuration ######

# sink:
#     # ## Deduplication of metering events, same as for server
#     # dedupe:
#     #     config:
#     #         address: 127.0.0.1:6379
#     #         database: 0
#     #         expiration: 24h
#     #         password: ""
#     #         sentinel:
#     #             enabled: false
#     #             mastername: ""
#     #         size: 128
#     #         tls:
#     #             enabled: false
#     #             insecureskipverify: false
#     #         username: ""
#     #     driver: memory
#     #     enabled: false
#     groupid: openmeter-sink-worker
#     ## Maximum wait time for batched commits
#     maxcommitwait: 5s
#     ## Minimum event count for batched commits
#     mincommitcount: 500
#     ## Namespace refetch interval (used for event validation)
#     namespacerefetch: 15s


telemetry:
    # ## Telemetry address
    # address: :10000
    ## Logging configuration
    log:
        # ## Accepted values: json, text
        # format: json
        ## Minimum log level that should appear in the output
        level: debug # Default: info
    # ## Metrics configuration
    # ## Currently Prometheus and OpenTelemetry Metrics are supported
    # metrics:
    #     exporters:
    #         otlp:
    #             address: ""
    #             enabled: false
    #         prometheus:
    #             enabled: false
    # ## Tracing Config
    # trace:
    #     exporters:
    #         otlp:
    #             address: ""
    #             enabled: false
    #     ## Accepted values: always, never or a float between 0 and 1
    #     sampler: never

###### Meters ######

meters:
  # Sample meter to count API requests
  - slug: api_requests_total        # Unique identifier for the meter
    description: API Requests
    eventType: request              # Filter events by type
    aggregation: COUNT              # Aggregation method: COUNT, SUM, etc.
    groupBy:
      method: $.method              # HTTP Method: GET, POST, etc.
      route: $.route                # Route: /products/:product_id

  # Sample meter to count LLM Token Usage
  - slug: tokens_total
    description: AI Token Usage
    eventType: prompt               # Filter events by type
    aggregation: SUM
    valueProperty: $.tokens         # JSONPath to parse usage value
    groupBy:
      model: $.model                # AI model used: gpt4-turbo, etc.
      type: $.type                  # Prompt type: input, output, system
